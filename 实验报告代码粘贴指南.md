# 实验报告代码粘贴指南

## 三、代码实现（5分）

### 代码说明

本项目包含完整的核心代码实现，所有代码均已添加：
- ✅ **模块注释**：每个模块文件开头都有模块名称、作者信息、学号、模块功能说明
- ✅ **函数功能注释**：每个函数都有详细的 docstring，说明函数功能、参数和返回值
- ✅ **行注释**：关键代码行都有中文注释，解释业务逻辑和技术实现

### 核心代码文件

项目提供了两个版本的代码文件供实验报告使用：

1. **实验报告核心代码.py** - 精简版（推荐用于报告）
   - 包含三类核心功能：爬虫、数据库、机器学习
   - 代码简洁，便于粘贴到报告中

2. **实验报告完整代码.py** - 完整版（包含数据清洗）
   - 包含四类功能：爬虫、数据库、数据清洗、机器学习
   - 代码更完整，包含使用示例

### 代码粘贴方式

**方式一：直接粘贴核心函数（推荐）**

从 `实验报告核心代码.py` 中选择以下核心函数粘贴到报告中：

1. **网络爬虫代码**：
   - `crawl_financial_news()` - 从网站爬取金融新闻
   - `crawl_tushare_indices()` - 从 TuShare API 爬取股票指数数据

2. **数据库操作代码**：
   - `save_to_mysql()` - 保存数据到 MySQL
   - `load_from_mysql()` - 从 MySQL 读取数据

3. **机器学习算法代码**：
   - `run_regression()` - 线性回归算法
   - `run_classification()` - 逻辑回归分类算法
   - `run_clustering()` - KMeans 聚类算法

**方式二：粘贴完整代码文件**

直接将 `实验报告完整代码.py` 的全部内容粘贴到报告中（包含使用示例）。

---

## 代码结构说明

### 一、网络爬虫技术

```python
# 1. 使用 requests 库发送 HTTP 请求
resp = requests.get(url, timeout=10)

# 2. 使用 BeautifulSoup 解析 HTML
soup = BeautifulSoup(resp.text, "html.parser")

# 3. 使用 CSS 选择器提取数据
for a in soup.select("a.news-link"):
    title = a.get_text(strip=True)
    href = a.get("href", "")
```

**技术要点**：
- `requests`：HTTP 请求库，用于获取网页内容
- `BeautifulSoup`：HTML 解析库，用于提取结构化数据
- CSS 选择器：定位网页元素

### 二、数据库技术

```python
# 1. 使用 SQLAlchemy 创建数据库引擎（连接池）
engine = create_engine(url, pool_size=5, max_overflow=10)

# 2. 使用 pandas 保存数据到 MySQL
df.to_sql(table_name, engine, if_exists="append", index=False)

# 3. 使用 pandas 从 MySQL 读取数据
df = pd.read_sql(f"SELECT * FROM `{table_name}`", engine)
```

**技术要点**：
- `SQLAlchemy`：Python ORM 框架，实现数据库操作
- `pymysql`：MySQL 数据库驱动
- 连接池：提高数据库访问性能

### 三、数据清洗技术

```python
# 1. 删除重复数据
df = df.drop_duplicates()

# 2. 处理缺失值（数值列用中位数填充）
df[col].fillna(df[col].median(), inplace=True)

# 3. 异常值处理（IQR 方法）
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1
df[col] = df[col].clip(lower=Q1-1.5*IQR, upper=Q3+1.5*IQR)
```

**技术要点**：
- 缺失值处理：中位数填充、众数填充
- 异常值检测：IQR（四分位距）方法
- 数据类型转换：确保日期列为 datetime 类型

### 四、机器学习算法

#### 1. 回归算法（LinearRegression）

```python
# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# 创建并训练模型
model = LinearRegression()
model.fit(X_train, y_train)

# 评估模型
r2 = model.score(X_test, y_test)  # R² 得分
```

**应用场景**：预测股票收盘价、指数点位、收益率等连续值

#### 2. 分类算法（LogisticRegression）

```python
# 将连续目标变量离散化为二分类
median = data[target_col].median()
data["label"] = (data[target_col] >= median).astype(int)

# 特征标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# 训练分类器
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train_scaled, y_train)

# 评估模型
acc = clf.score(X_test_scaled, y_test)  # 准确率
```

**应用场景**：判断股票涨跌方向、收益率高低分类

#### 3. 聚类算法（KMeans）

```python
# 特征标准化（KMeans 对距离敏感）
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 执行聚类
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X_scaled)
```

**应用场景**：股票分组、客户分群、市场状态识别

---

## 代码注释要求检查清单

在粘贴代码前，请确认：

- [ ] 每个文件开头有模块注释（模块名称、作者、学号、功能说明）
- [ ] 每个函数都有函数注释（函数名称、功能、参数、返回值）
- [ ] 关键代码行都有行注释（解释业务逻辑）
- [ ] 导入语句有说明（使用的库和模块）
- [ ] 算法实现有注释（训练过程、评估指标）

---

## 注意事项

1. **代码格式**：粘贴代码时保持缩进格式，使用代码块格式
2. **代码长度**：如果代码过长，可以只粘贴核心函数，省略使用示例
3. **注释完整性**：确保所有注释都包含在粘贴的代码中
4. **技术说明**：在代码后可以添加简短的技术说明，解释关键实现点

---

## 推荐粘贴内容

**最小化版本**（适合报告空间有限）：
- `crawl_financial_news()` - 爬虫函数
- `save_to_mysql()` / `load_from_mysql()` - 数据库函数
- `run_regression()` / `run_classification()` / `run_clustering()` - 三个机器学习函数

**完整版本**（推荐）：
- 粘贴 `实验报告完整代码.py` 的全部内容（包含数据清洗和使用示例）

