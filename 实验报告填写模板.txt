================================================================================
                    实验报告填写内容（可直接复制使用）
================================================================================

二、问题描述和设计思路（请明确列出设计思路）（3分）

问题描述：

本实验设计并实现了一个金融数据与文献分析一体化系统。该系统能够从多个数据源（TuShare、Alpha Vantage、东方财富、新浪财经等）爬取不同类型的金融数据，包括股票指数行情、外汇汇率、金融新闻快讯等。系统对爬取的数据进行清洗和预处理后，存储到MySQL数据库中。用户可以通过前端界面选择不同的数据表和特征列，系统会自动应用三类机器学习算法（线性回归、逻辑回归分类、KMeans聚类）进行数据分析和预测，并将结果以可视化的方式展示给用户。

设计思路：

（1）数据爬取模块设计
使用 requests 库和 BeautifulSoup 从东方财富网爬取金融新闻标题和链接；通过 TuShare API 爬取中国主要股票指数（上证指数、深证成指、创业板指、沪深300、中证500）的日线行情数据；调用 Alpha Vantage API 获取外汇汇率数据（USD/CNY、USD/GBP、USD/JPY、USD/EUR）；从新浪财经、东方财富等网站爬取金融快讯数据，支持关键词搜索和日期范围筛选。所有爬取的数据经过初步清洗（去重、去噪、格式统一）后准备入库。

（2）数据库存储与数据清洗模块设计
使用 MySQL 作为数据存储后端，通过 SQLAlchemy 实现 ORM 映射和连接池管理；设计多个数据表结构：ts_index_daily（指数日线）、fx_usdcny、fx_usdgbp、fx_usdjpy、fx_usdeur（外汇数据）、ts_flash（快讯）、ts_stock_daily（个股日线）等；实现数据清洗功能：缺失值处理、数据类型转换、异常值检测、数据标准化；使用 pandas 进行数据预处理，包括特征工程（如计算收益率、涨跌幅等衍生指标）。

（3）机器学习算法模块设计
回归算法：使用 sklearn.linear_model.LinearRegression 实现线性回归，用于预测连续型目标变量（如股价、收益率），评估指标包括 R² 和均方误差；分类算法：使用 sklearn.linear_model.LogisticRegression 实现逻辑回归二分类，将连续目标变量按中位数离散化为"高/低"两类，评估指标为准确率；聚类算法：使用 sklearn.cluster.KMeans 实现K均值聚类，对金融数据进行无监督分群（如股票分组、客户分群），默认聚类数为3，使用标准化后的特征进行聚类。所有算法均采用训练集/测试集划分（7:3），使用 StandardScaler 进行特征标准化，确保不同量纲的特征具有可比性。

（4）前后端交互设计
后端使用 Flask 框架提供 RESTful API，前端使用 HTML/JavaScript + Bootstrap + ECharts 构建交互界面；前端通过表单控件输入爬虫参数（关键词、数据源、日期范围等），后端返回 JSON 格式的数据和模型结果；使用 ECharts 实现多种图表可视化：折线图（指数走势）、柱状图（涨跌幅对比）、饼图（分类占比）、散点图（相关性分析）、箱线图（分布特征）；支持分析结果导出为 CSV、JSON、TXT 文本报告以及 PNG 静态图像。

（5）系统容错与性能优化
实现多层容错机制：外部API调用失败时自动回退到数据库缓存或示例数据；数据库写入失败不影响前端展示，仅记录警告日志；使用连接池技术提高数据库访问性能，设置合理的超时和重试机制；对TuShare API调用实现退避重试策略，避免频率限制导致的失败。

================================================================================

三、代码实现（5分）

代码文件说明：

项目包含以下主要代码文件，所有代码均已添加模块注释、函数功能注释和行注释：

1. app.py（2880行）- Flask 后端主程序
   - 模块注释：包含作者信息、学号、模块功能说明
   - 函数注释：每个API路由函数都有详细的docstring
   - 行注释：关键业务逻辑和数据处理步骤都有中文注释

2. crawler_ml.py（328行）- 爬虫和机器学习核心模块
   - 模块注释：说明爬虫、数据清洗、数据库操作、机器学习功能
   - 函数注释：crawl_financial_news、save_to_mysql、run_regression、run_classification、run_clustering 等函数都有完整注释
   - 行注释：数据清洗步骤、模型训练过程都有详细说明

3. analysis.py（321行）- 数据分析和可视化数据生成模块
   - 模块注释：说明数据分析、统计计算、图表数据准备功能
   - 函数注释：analyze_financial_dataframe、load_builtin_dataset 等函数都有注释
   - 行注释：统计计算、数据转换步骤都有说明

4. ai_helper.py - AI大模型调用封装模块
   - 模块注释：说明情感分析、文本摘要功能
   - 函数注释：analyze_sentiment、summarize_financial_text 等函数都有注释

5. utils.py - 工具函数模块
   - 模块注释：说明错误处理、日志记录、数据验证功能
   - 函数注释：handle_api_errors、validate_dataframe 等函数都有注释

6. db_config.py - 数据库配置模块
   - 包含MySQL连接配置信息

7. templates/index.html - 前端HTML模板
   - 包含前端交互界面和JavaScript代码

代码特点：

✅ 所有模块文件开头都有模块注释，包含：
   - 模块名称
   - 作者信息（姓名、学号）
   - 模块功能说明

✅ 所有函数都有函数功能注释（docstring），包含：
   - 函数名称
   - 函数功能
   - 参数说明
   - 返回值说明

✅ 关键代码行都有行注释，说明：
   - 业务逻辑
   - 数据处理步骤
   - 算法实现细节
   - 技术要点

代码已打包为：小组序号_报告2.rar

================================================================================

关键技术说明：

1. 网络爬虫技术：
   - requests：HTTP请求库，用于获取网页内容
   - BeautifulSoup：HTML解析库，用于提取结构化数据
   - Selenium：动态网页爬取（可选）

2. 数据库技术：
   - MySQL：关系型数据库，存储爬取和清洗后的数据
   - SQLAlchemy：Python ORM框架，实现数据库操作
   - pymysql：MySQL数据库驱动

3. 数据清洗与分析方法：
   - pandas：数据处理和分析库
   - numpy：数值计算库
   - 数据清洗：缺失值处理、异常值检测、数据类型转换

4. 机器学习算法：
   - 回归：sklearn.linear_model.LinearRegression（线性回归）
   - 分类：sklearn.linear_model.LogisticRegression（逻辑回归）
   - 聚类：sklearn.cluster.KMeans（K均值聚类）

================================================================================

